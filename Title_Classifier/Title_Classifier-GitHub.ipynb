{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Greg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Greg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classify titles based on word commonality and string content\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn import model_selection, svm, neighbors, preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "nltk.download('stopwords')\n",
    "home = str(Path.home())\n",
    "print(home)\n",
    "# Variable fields to adapt to different data sets --------------------------------------------------------------\n",
    "# Rank your role-levels in this dictionary\n",
    "values_to_replace = {'clevel': 1, 'vplevel': 2, 'directorlevel': 3, 'managerlevel': 4, 'staff': 5}\n",
    "# Level field in your data\n",
    "level_field = 'Management Level'\n",
    "# Title Field in your data\n",
    "title_field = 'Title'\n",
    "\n",
    "# st.stem() sklearn's word stemming algorithm\n",
    "st = nltk.stem.snowball.SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "# sklearn's vectorizor for bag of words analysis\n",
    "count_vect = sklearn.feature_extraction.text.CountVectorizer()\n",
    "TfidfVectorizer = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "# sklearn's normalizer to convert to zero-mean\n",
    "normalizer = preprocessing.Normalizer(copy=True, norm='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data / Process Functions-----------------------------------------------------------------------------------------\n",
    "\n",
    "# SQL Connection to Source File\n",
    "db = sqlite3.connect(\n",
    "    '{}\\\\directories\\\\database.db'.format(home))\n",
    "contacts2 = pd.read_sql(\"\"\"SELECT ContactID, C_EmailAddress,\n",
    "                        C_Title, C_Management_Level FROM contacts;\"\"\", con=db)\n",
    "db.close()\n",
    "\n",
    "contacts = pd.read_excel('{}\\\\OneDrive - Softchoice\\\\Documents\\\\PyCharmProjects\\\\Contact-Ranking\\\\Training_All_Conacts - Unique.xlsx'.format(home))\n",
    "contacts.fillna(inplace=True, value=\"\")\n",
    "\n",
    "\n",
    "# Training Data Set, if you want to use separate training data\n",
    "def import_training_data():\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        '{}\\\\OneDrive - Softchoice\\\\Documents\\\\PyCharmProjects\\\\Contact-Ranking\\\\Training_Export2.csv'.format(home))\n",
    "    # df = df[~df['Management Level'].str.contains(\"Senior-level manager\")]\n",
    "    df = df[['Title', 'Management Level', 'TitleFormatted']]\n",
    "    df.rename(index=str, columns={'Title': title_field, 'Management Level': level_field}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Import Title Abbreviations/replacements to improve accuracy\n",
    "title_abrev = pd.read_excel(\n",
    "    '{}\\\\OneDrive - Softchoice\\\\Documents\\\\PyCharmProjects\\\\Contact-Ranking\\\\title_abrev.xlsx'.format(home), sep=',')\n",
    "title_abrev.Title = title_abrev.Title.str.split(',').str[0].str.lower()\n",
    "title_abrev.to_pickle('title_abrev.p')\n",
    "\n",
    "\n",
    "def replace_str(series):\n",
    "    \"\"\"\n",
    "    A short function to replace any abbreviations with their full form\n",
    "    :param series: series to be cleansed\n",
    "    :return: the cleansed series\n",
    "    \"\"\"\n",
    "    print(series.tail())\n",
    "    for a, t in zip(title_abrev.Abrev, title_abrev.Title):\n",
    "        pattern = re.compile(r\"\\b{}\\b\".format(re.escape(a)), flags=re.IGNORECASE)\n",
    "#         print(a, t)\n",
    "        series = series.apply(lambda x: re.sub(pattern, t, x))\n",
    "    print('Replaced')\n",
    "    print(series.tail())\n",
    "    return series\n",
    "\n",
    "\n",
    "def process(df):\n",
    "    \"\"\"\n",
    "    The main processing stem for data inputs\n",
    "    :param df: data frame to be cleansed\n",
    "    :return: cleansed data frame\n",
    "    \"\"\"\n",
    "    df[level_field] = df[level_field].str.lower().str.replace('[^\\w\\s]', '')\n",
    "    df[level_field] = df[level_field].map(values_to_replace)\n",
    "    df['TitleFormatted'] = df[title_field].str.lower().str.replace('[^\\w\\s]', ' ').str.replace('\\s+', ' ')\n",
    "    df['TitleFormatted'] = replace_str(df['TitleFormatted'])  # Use function to replace abbreviations and misspellings\n",
    "    df['TitleFormatted'] = df['TitleFormatted'].apply(\n",
    "        lambda row: ' '.join([st.stem(y) for y in row.split(\" \")]))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing contact data.\n",
      "58882     ceo and director\n",
      "58883     cio and director\n",
      "58884      cto and directo\n",
      "58885    ciso and director\n",
      "58886     cno and director\n",
      "Name: TitleFormatted, dtype: object\n",
      "Replaced\n",
      "58882               chief executive officer and director\n",
      "58883             chief information officer and director\n",
      "58884              chief technology officer and director\n",
      "58885    chief information security officer and director\n",
      "58886                 chief nursing officer and director\n",
      "Name: TitleFormatted, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Process Data --------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"Processing contact data.\")\n",
    "contacts = process(contacts)\n",
    "# print(contacts[level_field])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rainking_data = import_training_data()\n",
    "\n",
    "# Hot Swap Training Data Set\n",
    "# training_contacts = rainking_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming titles to vectors.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "# Split data set\n",
    "contacts[level_field].replace('', np.nan, inplace=True)\n",
    "data_set = contacts[pd.notnull(contacts[level_field])]\n",
    "\n",
    "print(\"Transforming titles to vectors.\")\n",
    "X = TfidfVectorizer.fit_transform(data_set['TitleFormatted'].values)\n",
    "y = data_set[level_field]\n",
    "\n",
    "f = open(\n",
    "        '{}\\\\Directory\\\\Title_Vectorizor.pickle'.format(home), 'wb')\n",
    "pickle.dump(TfidfVectorizer, f)\n",
    "f.close()\n",
    "\n",
    "# Normalize the data set to optimise for Linear SVC\n",
    "X = normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58887, 8537)\n",
      "Count of ex: 3002\n"
     ]
    }
   ],
   "source": [
    "stem = \"ex\"\n",
    "\n",
    "# print(data_set.head()) # Describe the data_set\n",
    "print(X.shape)\n",
    "print(\"Count of {word}: {count}\".format(count=str(TfidfVectorizer.vocabulary_.get(u'{}'.format(stem))), word=stem))\n",
    "# print(y.shape)\n",
    "# print(bag_of_words.vocabulary_.get('man')) # Print how many times a particular stem appears\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier.\n",
      "Estimated accuracy is: 0.8970962812022415%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train Classifier --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Options: M = Multinomial, B = Bernoulli, SVM = SVM\n",
    "MN = 'SVM'\n",
    "\n",
    "# Splits the data into training and testing data sets (20%)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "if MN == 'B':\n",
    "    clf = BernoulliNB()\n",
    "elif MN == 'SVM':\n",
    "#     clf = svm.LinearSVC()\n",
    "    clf = sklearn.linear_model.SGDClassifier(n_jobs=-1, alpha=1e-3)\n",
    "else:\n",
    "    clf = MultinomialNB()\n",
    "print(\"Training classifier.\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "if MN == 'B':\n",
    "    f = open(\n",
    "        '{}\\\\Directory\\\\Title_Classifier_B.pickle'.format(home), 'wb')\n",
    "elif MN == 'SVM':\n",
    "    f = open(\n",
    "        '{}\\\\Directory\\\\Title_Classifier_SVM.pickle'.format(home), 'wb')\n",
    "else:\n",
    "    f = open(\n",
    "        '{}\\\\Directory\\\\Title_Classifier_MN.pickle'.format(home), 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "# Return Accuracy score\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Estimated accuracy is: {}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217407               \n",
      "217408               \n",
      "217409               \n",
      "217410               \n",
      "217411    it director\n",
      "Name: TitleFormatted, dtype: object\n",
      "Replaced\n",
      "217407                                   \n",
      "217408                                   \n",
      "217409                                   \n",
      "217410                                   \n",
      "217411    information technology director\n",
      "Name: TitleFormatted, dtype: object\n",
      "Predicting management level.\n",
      "Finished Predicting.\n",
      "Adding column to highlight differences in contact table.\n",
      "       Management Level  Management Level_P\n",
      "count     112640.000000       217412.000000\n",
      "mean           3.534570            3.954671\n",
      "std            1.353595            1.310041\n",
      "min            1.000000            1.000000\n",
      "25%            3.000000            3.000000\n",
      "50%            4.000000            5.000000\n",
      "75%            5.000000            5.000000\n",
      "max            5.000000            5.000000\n",
      "Exporting predictions.\n"
     ]
    }
   ],
   "source": [
    "# Analyse -------------------------------------------------------------------------------------------------------------\n",
    "# Create a copy of original data set to analyze\n",
    "contacts2.rename(index=str, columns={'C_Management_Level1': 'Management Level','C_Title': 'Title'}, inplace=True)\n",
    "contacts2 = process(contacts2)\n",
    "X_process = TfidfVectorizer.transform(contacts2['TitleFormatted'])\n",
    "print(\"Predicting management level.\")\n",
    "prediction = clf.predict(X_process)\n",
    "contacts2[level_field+'_P'] = prediction\n",
    "print(\"Finished Predicting.\")\n",
    "\n",
    "# Create a column that highlights where the prediction is different than the current value ----------------------------\n",
    "print(\"Adding column to highlight differences in contact table.\")\n",
    "contacts2[\"Is_Same\"] = np.where(contacts2[level_field] == contacts2[level_field+'_P'], 'yes', 'no')\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# drop working column and export to csv\n",
    "contacts2.drop('TitleFormatted', axis=1, inplace=True)\n",
    "print(contacts2.describe())\n",
    "print(\"Exporting predictions.\")\n",
    "contacts2.to_csv('test_predictions.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
